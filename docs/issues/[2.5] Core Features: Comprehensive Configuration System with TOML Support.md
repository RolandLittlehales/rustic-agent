# [2.5] Core Features: Comprehensive Configuration System with TOML Support

## Overview

### Current State
- Basic configuration with limited options
- Hardcoded defaults without flexibility
- No configuration validation or hot-reloading
- Limited environment-specific settings

### Target State
- Full TOML configuration with schema validation
- Configuration profiles and environment-specific settings
- Hot-reloading and dynamic configuration updates
- Integration with all Phase 1 and Phase 2 systems
- Configuration versioning and migration support

### Why This Matters
- **Flexibility**: Comprehensive configuration options for all system components
- **Maintainability**: Centralized configuration management with validation
- **Deployment**: Environment-specific configurations without code changes
- **Operations**: Hot-reloading for zero-downtime configuration updates

## Technical Requirements

### 1. TOML Configuration Schema System

```rust
use std::collections::{HashMap, HashSet};
use std::path::{Path, PathBuf};
use std::sync::Arc;
use tokio::sync::{RwLock, watch};
use serde::{Deserialize, Serialize};
use toml::{Table, Value};
use uuid::Uuid;
use chrono::{DateTime, Utc, Duration};

/// Comprehensive application configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AppConfiguration {
    /// Global application settings
    pub app: AppSettings,
    
    /// Claude API configuration
    pub claude: ClaudeConfig,
    
    /// Tool system configuration
    pub tools: ToolsConfig,
    
    /// Workflow orchestration configuration
    pub workflows: WorkflowConfig,
    
    /// Streaming configuration
    pub streaming: StreamingConfig,
    
    /// Error handling configuration
    pub error_handling: ErrorHandlingConfig,
    
    /// Security and authentication
    pub security: SecurityConfig,
    
    /// Logging and monitoring
    pub logging: LoggingConfig,
    
    /// Performance tuning
    pub performance: PerformanceConfig,
    
    /// Development and debugging
    pub development: DevelopmentConfig,
    
    /// Environment-specific overrides
    pub environments: HashMap<String, EnvironmentOverrides>,
}

/// Global application settings
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AppSettings {
    /// Application name and version
    pub name: String,
    pub version: String,
    
    /// Environment (development, staging, production)
    pub environment: String,
    
    /// Application mode
    pub mode: ApplicationMode,
    
    /// Timezone settings
    pub timezone: String,
    
    /// Feature flags
    pub features: HashMap<String, bool>,
    
    /// Resource limits
    pub limits: ResourceLimits,
    
    /// Data storage configuration
    pub storage: StorageConfig,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum ApplicationMode {
    Development,
    Testing,
    Staging,
    Production,
}

/// Claude API configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClaudeConfig {
    /// API configuration
    pub api: ClaudeApiConfig,
    
    /// Model settings
    pub models: ClaudeModelConfig,
    
    /// Request configuration
    pub requests: ClaudeRequestConfig,
    
    /// Response handling
    pub responses: ClaudeResponseConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClaudeApiConfig {
    /// Base URL for Claude API
    pub base_url: String,
    
    /// API key (can be environment variable reference)
    pub api_key: ConfigValue<String>,
    
    /// Request timeout
    pub timeout: ConfigDuration,
    
    /// Connection settings
    pub connection: ConnectionConfig,
    
    /// Retry configuration
    pub retry: RetryConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClaudeModelConfig {
    /// Default model to use
    pub default_model: String,
    
    /// Model-specific configurations
    pub model_configs: HashMap<String, ModelSettings>,
    
    /// Model selection strategy
    pub selection_strategy: ModelSelectionStrategy,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelSettings {
    /// Maximum tokens for this model
    pub max_tokens: Option<u32>,
    
    /// Temperature setting
    pub temperature: Option<f64>,
    
    /// Top-p setting
    pub top_p: Option<f64>,
    
    /// Model-specific timeout
    pub timeout: Option<ConfigDuration>,
    
    /// Cost per token (for budgeting)
    pub cost_per_token: Option<f64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ModelSelectionStrategy {
    Fixed,
    LoadBalanced,
    CostOptimized,
    PerformanceOptimized,
    Custom(String),
}

/// Tool system configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolsConfig {
    /// Tool execution settings
    pub execution: ToolExecutionConfig,
    
    /// Parallel execution configuration
    pub parallel: ParallelExecutionConfig,
    
    /// Tool-specific configurations
    pub tool_configs: HashMap<String, ToolSpecificConfig>,
    
    /// Security settings for tools
    pub security: ToolSecurityConfig,
    
    /// Resource management
    pub resources: ToolResourceConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolExecutionConfig {
    /// Default timeout for tool execution
    pub default_timeout: ConfigDuration,
    
    /// Maximum concurrent tools
    pub max_concurrent: usize,
    
    /// Tool result caching
    pub caching: ToolCachingConfig,
    
    /// Execution monitoring
    pub monitoring: ToolMonitoringConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ParallelExecutionConfig {
    /// Maximum concurrent executions
    pub max_concurrency: usize,
    
    /// Resource allocation limits
    pub resource_limits: ResourceLimits,
    
    /// Scheduling algorithm
    pub scheduler: SchedulerConfig,
    
    /// Dependency resolution
    pub dependency_resolution: DependencyConfig,
}

/// Workflow configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowConfig {
    /// Workflow execution settings
    pub execution: WorkflowExecutionConfig,
    
    /// Data transformation settings
    pub transformation: DataTransformationConfig,
    
    /// Error handling for workflows
    pub error_handling: WorkflowErrorConfig,
    
    /// Workflow storage and persistence
    pub storage: WorkflowStorageConfig,
    
    /// Monitoring and metrics
    pub monitoring: WorkflowMonitoringConfig,
}

/// Streaming configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StreamingConfig {
    /// Server-Sent Events configuration
    pub sse: SSEConfig,
    
    /// Event routing and filtering
    pub routing: EventRoutingConfig,
    
    /// Streaming optimization
    pub optimization: StreamingOptimizationConfig,
    
    /// Connection management
    pub connections: ConnectionManagementConfig,
    
    /// Quality settings
    pub quality: QualityConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SSEConfig {
    /// Maximum concurrent connections
    pub max_connections: usize,
    
    /// Connection timeout
    pub connection_timeout: ConfigDuration,
    
    /// Heartbeat interval
    pub heartbeat_interval: ConfigDuration,
    
    /// Event buffer size
    pub buffer_size: usize,
    
    /// Compression settings
    pub compression: CompressionConfig,
}

/// Error handling configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorHandlingConfig {
    /// Error classification settings
    pub classification: ErrorClassificationConfig,
    
    /// Retry strategies
    pub retry: RetryStrategiesConfig,
    
    /// Circuit breaker settings
    pub circuit_breaker: CircuitBreakerConfig,
    
    /// Recovery mechanisms
    pub recovery: RecoveryConfig,
    
    /// Error analytics
    pub analytics: ErrorAnalyticsConfig,
}

/// Security configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SecurityConfig {
    /// Authentication settings
    pub authentication: AuthenticationConfig,
    
    /// Authorization settings
    pub authorization: AuthorizationConfig,
    
    /// Encryption settings
    pub encryption: EncryptionConfig,
    
    /// Whitelist configuration
    pub whitelist: WhitelistConfig,
    
    /// Security monitoring
    pub monitoring: SecurityMonitoringConfig,
}

/// Performance configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceConfig {
    /// Memory management
    pub memory: MemoryConfig,
    
    /// CPU optimization
    pub cpu: CpuConfig,
    
    /// I/O optimization
    pub io: IoConfig,
    
    /// Caching configuration
    pub caching: CachingConfig,
    
    /// Connection pooling
    pub connection_pooling: ConnectionPoolingConfig,
}

/// Configuration value that can be a literal value or environment variable reference
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum ConfigValue<T> {
    /// Literal value
    Value(T),
    /// Environment variable reference
    EnvVar { env: String, default: Option<T> },
    /// External configuration reference
    External { source: String, key: String, default: Option<T> },
}

/// Duration configuration with multiple format support
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum ConfigDuration {
    /// Duration in seconds
    Seconds(u64),
    /// Duration string (e.g., "30s", "5m", "1h")
    String(String),
    /// Precise duration specification
    Precise {
        seconds: Option<u64>,
        milliseconds: Option<u64>,
        microseconds: Option<u64>,
    },
}

impl ConfigDuration {
    pub fn to_std_duration(&self) -> Result<std::time::Duration, ConfigError> {
        match self {
            ConfigDuration::Seconds(s) => Ok(std::time::Duration::from_secs(*s)),
            ConfigDuration::String(s) => parse_duration_string(s),
            ConfigDuration::Precise { seconds, milliseconds, microseconds } => {
                let mut duration = std::time::Duration::new(0, 0);
                if let Some(s) = seconds {
                    duration += std::time::Duration::from_secs(*s);
                }
                if let Some(ms) = milliseconds {
                    duration += std::time::Duration::from_millis(*ms);
                }
                if let Some(us) = microseconds {
                    duration += std::time::Duration::from_micros(*us);
                }
                Ok(duration)
            }
        }
    }
}

/// Configuration manager with validation and hot-reloading
pub struct ConfigurationManager {
    /// Current configuration
    config: Arc<RwLock<AppConfiguration>>,
    
    /// Configuration schema validator
    validator: Arc<ConfigValidator>,
    
    /// File watcher for hot-reloading
    file_watcher: Arc<ConfigFileWatcher>,
    
    /// Configuration change notifier
    change_notifier: watch::Sender<ConfigurationEvent>,
    
    /// Configuration sources
    sources: Vec<Box<dyn ConfigurationSource + Send + Sync>>,
    
    /// Environment processor
    env_processor: Arc<EnvironmentProcessor>,
    
    /// Configuration history for rollback
    history: Arc<RwLock<ConfigurationHistory>>,
}

/// Configuration source trait
#[async_trait]
pub trait ConfigurationSource: Send + Sync {
    /// Load configuration from this source
    async fn load_config(&self) -> Result<Table, ConfigError>;
    
    /// Watch for configuration changes
    async fn watch_changes(&self) -> Result<ConfigChangeStream, ConfigError>;
    
    /// Source priority (higher = more priority)
    fn priority(&self) -> i32;
    
    /// Source name for identification
    fn name(&self) -> &str;
}

/// File-based configuration source
pub struct FileConfigurationSource {
    file_path: PathBuf,
    watch_enabled: bool,
}

#[async_trait]
impl ConfigurationSource for FileConfigurationSource {
    async fn load_config(&self) -> Result<Table, ConfigError> {
        let content = tokio::fs::read_to_string(&self.file_path).await
            .map_err(|e| ConfigError::FileRead {
                path: self.file_path.clone(),
                error: e.to_string(),
            })?;
        
        toml::from_str(&content)
            .map_err(|e| ConfigError::ParseError {
                source: self.file_path.to_string_lossy().to_string(),
                error: e.to_string(),
            })
    }
    
    async fn watch_changes(&self) -> Result<ConfigChangeStream, ConfigError> {
        if !self.watch_enabled {
            return Err(ConfigError::WatchingNotEnabled);
        }
        
        // Implementation would use notify crate or similar
        todo!("Implement file watching")
    }
    
    fn priority(&self) -> i32 {
        100 // Base priority for file sources
    }
    
    fn name(&self) -> &str {
        "file"
    }
}

/// Environment variable configuration source
pub struct EnvironmentConfigurationSource {
    prefix: String,
    mapping: HashMap<String, String>,
}

#[async_trait]
impl ConfigurationSource for EnvironmentConfigurationSource {
    async fn load_config(&self) -> Result<Table, ConfigError> {
        let mut config = Table::new();
        
        for (env_key, config_path) in &self.mapping {
            if let Ok(value) = std::env::var(env_key) {
                self.set_nested_value(&mut config, config_path, value)?;
            }
        }
        
        Ok(config)
    }
    
    async fn watch_changes(&self) -> Result<ConfigChangeStream, ConfigError> {
        // Environment variables don't typically change during runtime
        Err(ConfigError::WatchingNotSupported)
    }
    
    fn priority(&self) -> i32 {
        200 // Higher priority than files
    }
    
    fn name(&self) -> &str {
        "environment"
    }
}

impl EnvironmentConfigurationSource {
    fn set_nested_value(&self, table: &mut Table, path: &str, value: String) -> Result<(), ConfigError> {
        let parts: Vec<&str> = path.split('.').collect();
        let mut current = table;
        
        // Navigate to the parent of the target key
        for part in &parts[..parts.len() - 1] {
            current = current
                .entry(part)
                .or_insert_with(|| Value::Table(Table::new()))
                .as_table_mut()
                .ok_or_else(|| ConfigError::InvalidPath(path.to_string()))?;
        }
        
        // Set the final value
        let final_key = parts.last().unwrap();
        
        // Try to parse as different types
        let parsed_value = if let Ok(b) = value.parse::<bool>() {
            Value::Boolean(b)
        } else if let Ok(i) = value.parse::<i64>() {
            Value::Integer(i)
        } else if let Ok(f) = value.parse::<f64>() {
            Value::Float(f)
        } else {
            Value::String(value)
        };
        
        current.insert(final_key.to_string(), parsed_value);
        Ok(())
    }
}

impl ConfigurationManager {
    pub fn new() -> Self {
        let (tx, _) = watch::channel(ConfigurationEvent::Loaded);
        
        Self {
            config: Arc::new(RwLock::new(AppConfiguration::default())),
            validator: Arc::new(ConfigValidator::new()),
            file_watcher: Arc::new(ConfigFileWatcher::new()),
            change_notifier: tx,
            sources: Vec::new(),
            env_processor: Arc::new(EnvironmentProcessor::new()),
            history: Arc::new(RwLock::new(ConfigurationHistory::new())),
        }
    }
    
    /// Add configuration source
    pub fn add_source(&mut self, source: Box<dyn ConfigurationSource + Send + Sync>) {
        self.sources.push(source);
        
        // Sort sources by priority
        self.sources.sort_by(|a, b| b.priority().cmp(&a.priority()));
    }
    
    /// Load configuration from all sources
    pub async fn load_configuration(&self) -> Result<(), ConfigError> {
        let mut merged_config = Table::new();
        
        // Load from all sources in priority order
        for source in &self.sources {
            match source.load_config().await {
                Ok(config) => {
                    self.merge_configuration(&mut merged_config, config)?;
                }
                Err(e) => {
                    // Log error but continue with other sources
                    eprintln!("Failed to load from source {}: {}", source.name(), e);
                }
            }
        }
        
        // Process environment variables
        self.env_processor.process_env_vars(&mut merged_config).await?;
        
        // Validate configuration
        let app_config = self.validator.validate_and_deserialize(merged_config).await?;
        
        // Store configuration
        let old_config = {
            let mut config = self.config.write().await;
            let old = config.clone();
            *config = app_config;
            old
        };
        
        // Add to history
        self.history.write().await.add_version(old_config);
        
        // Notify change
        let _ = self.change_notifier.send(ConfigurationEvent::Loaded);
        
        Ok(())
    }
    
    /// Get current configuration
    pub async fn get_config(&self) -> AppConfiguration {
        self.config.read().await.clone()
    }
    
    /// Get specific configuration section
    pub async fn get_section<T>(&self, section: ConfigSection) -> Result<T, ConfigError>
    where
        T: for<'de> Deserialize<'de> + Clone,
    {
        let config = self.config.read().await;
        
        let value = match section {
            ConfigSection::App => serde_json::to_value(&config.app)?,
            ConfigSection::Claude => serde_json::to_value(&config.claude)?,
            ConfigSection::Tools => serde_json::to_value(&config.tools)?,
            ConfigSection::Workflows => serde_json::to_value(&config.workflows)?,
            ConfigSection::Streaming => serde_json::to_value(&config.streaming)?,
            ConfigSection::ErrorHandling => serde_json::to_value(&config.error_handling)?,
            ConfigSection::Security => serde_json::to_value(&config.security)?,
            ConfigSection::Performance => serde_json::to_value(&config.performance)?,
        };
        
        Ok(serde_json::from_value(value)?)
    }
    
    /// Update configuration section
    pub async fn update_section<T>(
        &self,
        section: ConfigSection,
        new_config: T,
    ) -> Result<(), ConfigError>
    where
        T: Serialize,
    {
        let mut config = self.config.write().await;
        let old_config = config.clone();
        
        // Update the specific section
        match section {
            ConfigSection::App => {
                config.app = serde_json::from_value(serde_json::to_value(new_config)?)?;
            }
            ConfigSection::Claude => {
                config.claude = serde_json::from_value(serde_json::to_value(new_config)?)?;
            }
            ConfigSection::Tools => {
                config.tools = serde_json::from_value(serde_json::to_value(new_config)?)?;
            }
            ConfigSection::Workflows => {
                config.workflows = serde_json::from_value(serde_json::to_value(new_config)?)?;
            }
            ConfigSection::Streaming => {
                config.streaming = serde_json::from_value(serde_json::to_value(new_config)?)?;
            }
            ConfigSection::ErrorHandling => {
                config.error_handling = serde_json::from_value(serde_json::to_value(new_config)?)?;
            }
            ConfigSection::Security => {
                config.security = serde_json::from_value(serde_json::to_value(new_config)?)?;
            }
            ConfigSection::Performance => {
                config.performance = serde_json::from_value(serde_json::to_value(new_config)?)?;
            }
        }
        
        // Validate the updated configuration
        self.validator.validate_configuration(&*config).await?;
        
        // Add to history
        self.history.write().await.add_version(old_config);
        
        // Notify change
        let _ = self.change_notifier.send(ConfigurationEvent::Updated(section));
        
        Ok(())
    }
    
    /// Subscribe to configuration changes
    pub fn subscribe_to_changes(&self) -> watch::Receiver<ConfigurationEvent> {
        self.change_notifier.subscribe()
    }
    
    /// Start watching for configuration file changes
    pub async fn start_hot_reloading(&self) -> Result<(), ConfigError> {
        let manager = self.clone();
        
        tokio::spawn(async move {
            // Implementation would watch for file changes and reload configuration
            loop {
                tokio::time::sleep(std::time::Duration::from_secs(1)).await;
                
                // Check for file changes
                if manager.file_watcher.has_changes().await {
                    if let Err(e) = manager.load_configuration().await {
                        eprintln!("Failed to reload configuration: {}", e);
                    }
                }
            }
        });
        
        Ok(())
    }
    
    /// Merge two TOML configurations
    fn merge_configuration(&self, base: &mut Table, overlay: Table) -> Result<(), ConfigError> {
        for (key, value) in overlay {
            match (base.get_mut(&key), value) {
                (Some(Value::Table(base_table)), Value::Table(overlay_table)) => {
                    // Recursively merge tables
                    self.merge_configuration(base_table, overlay_table)?;
                }
                _ => {
                    // Replace or insert the value
                    base.insert(key, value);
                }
            }
        }
        Ok(())
    }
}
```

### 2. Configuration Validation System

```rust
/// Configuration validator with schema enforcement
pub struct ConfigValidator {
    /// Configuration schema
    schema: Arc<ConfigSchema>,
    
    /// Custom validation rules
    custom_validators: HashMap<String, Box<dyn CustomValidator + Send + Sync>>,
    
    /// Validation cache
    validation_cache: Arc<RwLock<HashMap<String, ValidationResult>>>,
}

/// Configuration schema definition
#[derive(Debug, Clone)]
pub struct ConfigSchema {
    /// Schema for each configuration section
    pub sections: HashMap<String, SectionSchema>,
    
    /// Global validation rules
    pub global_rules: Vec<ValidationRule>,
    
    /// Schema version
    pub version: String,
}

#[derive(Debug, Clone)]
pub struct SectionSchema {
    /// Required fields
    pub required_fields: HashSet<String>,
    
    /// Field types and constraints
    pub field_constraints: HashMap<String, FieldConstraint>,
    
    /// Section-specific validation rules
    pub validation_rules: Vec<ValidationRule>,
    
    /// Dependencies between fields
    pub field_dependencies: Vec<FieldDependency>,
}

#[derive(Debug, Clone)]
pub enum FieldConstraint {
    /// String constraints
    String {
        min_length: Option<usize>,
        max_length: Option<usize>,
        pattern: Option<String>,
        allowed_values: Option<HashSet<String>>,
    },
    
    /// Number constraints
    Number {
        min: Option<f64>,
        max: Option<f64>,
        integer_only: bool,
    },
    
    /// Duration constraints
    Duration {
        min: Option<std::time::Duration>,
        max: Option<std::time::Duration>,
    },
    
    /// Array constraints
    Array {
        min_items: Option<usize>,
        max_items: Option<usize>,
        item_type: Option<Box<FieldConstraint>>,
    },
    
    /// Object constraints
    Object {
        required_keys: HashSet<String>,
        allowed_keys: Option<HashSet<String>>,
        key_constraints: HashMap<String, FieldConstraint>,
    },
    
    /// Custom validation function
    Custom(String),
}

#[derive(Debug, Clone)]
pub struct ValidationRule {
    pub name: String,
    pub description: String,
    pub rule_type: ValidationRuleType,
    pub severity: ValidationSeverity,
}

#[derive(Debug, Clone)]
pub enum ValidationRuleType {
    /// Field value validation
    FieldValue {
        field_path: String,
        constraint: FieldConstraint,
    },
    
    /// Cross-field validation
    CrossField {
        fields: Vec<String>,
        validator: String,
    },
    
    /// Business logic validation
    BusinessLogic {
        validator: String,
    },
    
    /// Performance validation
    Performance {
        validator: String,
    },
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum ValidationSeverity {
    Error,   // Configuration is invalid
    Warning, // Configuration is valid but not optimal
    Info,    // Information for the user
}

#[derive(Debug, Clone)]
pub struct ValidationResult {
    pub is_valid: bool,
    pub issues: Vec<ValidationIssue>,
    pub validated_at: DateTime<Utc>,
    pub validation_time: std::time::Duration,
}

#[derive(Debug, Clone)]
pub struct ValidationIssue {
    pub field_path: String,
    pub severity: ValidationSeverity,
    pub message: String,
    pub suggestion: Option<String>,
    pub rule_name: String,
}

/// Custom validator trait
pub trait CustomValidator: Send + Sync {
    fn validate(&self, value: &Value, context: &ValidationContext) -> Result<(), ValidationError>;
    fn name(&self) -> &str;
}

#[derive(Debug)]
pub struct ValidationContext {
    pub field_path: String,
    pub full_config: Table,
    pub environment: String,
}

impl ConfigValidator {
    pub fn new() -> Self {
        let mut validator = Self {
            schema: Arc::new(ConfigSchema::default()),
            custom_validators: HashMap::new(),
            validation_cache: Arc::new(RwLock::new(HashMap::new())),
        };
        
        // Register built-in validators
        validator.register_builtin_validators();
        
        validator
    }
    
    /// Validate and deserialize configuration
    pub async fn validate_and_deserialize(
        &self,
        config: Table,
    ) -> Result<AppConfiguration, ConfigError> {
        // Validate the configuration
        let validation_result = self.validate_table(&config).await?;
        
        if !validation_result.is_valid {
            let errors: Vec<_> = validation_result
                .issues
                .iter()
                .filter(|i| i.severity == ValidationSeverity::Error)
                .map(|i| i.message.clone())
                .collect();
            
            return Err(ConfigError::ValidationFailed(errors));
        }
        
        // Deserialize to AppConfiguration
        let value = Value::Table(config);
        toml::from_str(&toml::to_string(&value)?)
            .map_err(|e| ConfigError::DeserializationFailed(e.to_string()))
    }
    
    /// Validate configuration table
    async fn validate_table(&self, config: &Table) -> Result<ValidationResult, ConfigError> {
        let start_time = std::time::Instant::now();
        let mut issues = Vec::new();
        
        // Validate each section
        for (section_name, section_schema) in &self.schema.sections {
            if let Some(section_value) = config.get(section_name) {
                let section_issues = self
                    .validate_section(section_name, section_value, section_schema)
                    .await?;
                issues.extend(section_issues);
            } else if !section_schema.required_fields.is_empty() {
                issues.push(ValidationIssue {
                    field_path: section_name.clone(),
                    severity: ValidationSeverity::Error,
                    message: format!("Required section '{}' is missing", section_name),
                    suggestion: Some(format!("Add [{}] section to configuration", section_name)),
                    rule_name: "required_section".to_string(),
                });
            }
        }
        
        // Apply global validation rules
        for rule in &self.schema.global_rules {
            if let Some(rule_issues) = self.apply_validation_rule(rule, config).await? {
                issues.extend(rule_issues);
            }
        }
        
        let validation_time = start_time.elapsed();
        let is_valid = !issues.iter().any(|i| i.severity == ValidationSeverity::Error);
        
        Ok(ValidationResult {
            is_valid,
            issues,
            validated_at: Utc::now(),
            validation_time,
        })
    }
    
    /// Validate a configuration section
    async fn validate_section(
        &self,
        section_name: &str,
        section_value: &Value,
        schema: &SectionSchema,
    ) -> Result<Vec<ValidationIssue>, ConfigError> {
        let mut issues = Vec::new();
        
        if let Value::Table(table) = section_value {
            // Check required fields
            for required_field in &schema.required_fields {
                if !table.contains_key(required_field) {
                    issues.push(ValidationIssue {
                        field_path: format!("{}.{}", section_name, required_field),
                        severity: ValidationSeverity::Error,
                        message: format!("Required field '{}' is missing", required_field),
                        suggestion: Some(format!("Add {} to [{}] section", required_field, section_name)),
                        rule_name: "required_field".to_string(),
                    });
                }
            }
            
            // Validate field constraints
            for (field_name, constraint) in &schema.field_constraints {
                if let Some(field_value) = table.get(field_name) {
                    if let Some(issue) = self
                        .validate_field_constraint(
                            &format!("{}.{}", section_name, field_name),
                            field_value,
                            constraint,
                        )
                        .await?
                    {
                        issues.push(issue);
                    }
                }
            }
            
            // Apply section-specific validation rules
            for rule in &schema.validation_rules {
                if let Some(rule_issues) = self.apply_validation_rule(rule, &table.clone().into()).await? {
                    issues.extend(rule_issues);
                }
            }
            
            // Check field dependencies
            for dependency in &schema.field_dependencies {
                if let Some(dependency_issues) = self
                    .validate_field_dependency(section_name, table, dependency)
                    .await?
                {
                    issues.extend(dependency_issues);
                }
            }
        } else {
            issues.push(ValidationIssue {
                field_path: section_name.to_string(),
                severity: ValidationSeverity::Error,
                message: format!("Section '{}' must be a table", section_name),
                suggestion: Some(format!("Change {} to [{}] table format", section_name, section_name)),
                rule_name: "section_type".to_string(),
            });
        }
        
        Ok(issues)
    }
    
    /// Validate field constraint
    async fn validate_field_constraint(
        &self,
        field_path: &str,
        value: &Value,
        constraint: &FieldConstraint,
    ) -> Result<Option<ValidationIssue>, ConfigError> {
        match constraint {
            FieldConstraint::String {
                min_length,
                max_length,
                pattern,
                allowed_values,
            } => {
                if let Some(s) = value.as_str() {
                    // Check length constraints
                    if let Some(min) = min_length {
                        if s.len() < *min {
                            return Ok(Some(ValidationIssue {
                                field_path: field_path.to_string(),
                                severity: ValidationSeverity::Error,
                                message: format!("String too short (minimum {} characters)", min),
                                suggestion: None,
                                rule_name: "string_min_length".to_string(),
                            }));
                        }
                    }
                    
                    if let Some(max) = max_length {
                        if s.len() > *max {
                            return Ok(Some(ValidationIssue {
                                field_path: field_path.to_string(),
                                severity: ValidationSeverity::Error,
                                message: format!("String too long (maximum {} characters)", max),
                                suggestion: None,
                                rule_name: "string_max_length".to_string(),
                            }));
                        }
                    }
                    
                    // Check pattern
                    if let Some(pattern) = pattern {
                        let regex = regex::Regex::new(pattern)
                            .map_err(|e| ConfigError::InvalidPattern(e.to_string()))?;
                        
                        if !regex.is_match(s) {
                            return Ok(Some(ValidationIssue {
                                field_path: field_path.to_string(),
                                severity: ValidationSeverity::Error,
                                message: format!("String does not match required pattern: {}", pattern),
                                suggestion: None,
                                rule_name: "string_pattern".to_string(),
                            }));
                        }
                    }
                    
                    // Check allowed values
                    if let Some(allowed) = allowed_values {
                        if !allowed.contains(s) {
                            return Ok(Some(ValidationIssue {
                                field_path: field_path.to_string(),
                                severity: ValidationSeverity::Error,
                                message: format!("Value '{}' is not allowed", s),
                                suggestion: Some(format!("Allowed values: {:?}", allowed)),
                                rule_name: "string_allowed_values".to_string(),
                            }));
                        }
                    }
                } else {
                    return Ok(Some(ValidationIssue {
                        field_path: field_path.to_string(),
                        severity: ValidationSeverity::Error,
                        message: "Expected string value".to_string(),
                        suggestion: None,
                        rule_name: "type_mismatch".to_string(),
                    }));
                }
            }
            
            FieldConstraint::Number { min, max, integer_only } => {
                let num_value = if let Some(i) = value.as_integer() {
                    i as f64
                } else if let Some(f) = value.as_float() {
                    if *integer_only {
                        return Ok(Some(ValidationIssue {
                            field_path: field_path.to_string(),
                            severity: ValidationSeverity::Error,
                            message: "Expected integer value".to_string(),
                            suggestion: None,
                            rule_name: "integer_required".to_string(),
                        }));
                    }
                    f
                } else {
                    return Ok(Some(ValidationIssue {
                        field_path: field_path.to_string(),
                        severity: ValidationSeverity::Error,
                        message: "Expected number value".to_string(),
                        suggestion: None,
                        rule_name: "type_mismatch".to_string(),
                    }));
                };
                
                if let Some(min_val) = min {
                    if num_value < *min_val {
                        return Ok(Some(ValidationIssue {
                            field_path: field_path.to_string(),
                            severity: ValidationSeverity::Error,
                            message: format!("Value {} is below minimum {}", num_value, min_val),
                            suggestion: None,
                            rule_name: "number_min".to_string(),
                        }));
                    }
                }
                
                if let Some(max_val) = max {
                    if num_value > *max_val {
                        return Ok(Some(ValidationIssue {
                            field_path: field_path.to_string(),
                            severity: ValidationSeverity::Error,
                            message: format!("Value {} is above maximum {}", num_value, max_val),
                            suggestion: None,
                            rule_name: "number_max".to_string(),
                        }));
                    }
                }
            }
            
            FieldConstraint::Duration { min, max } => {
                // Parse duration value
                let duration = match value {
                    Value::Integer(i) => std::time::Duration::from_secs(*i as u64),
                    Value::String(s) => parse_duration_string(s)?,
                    _ => {
                        return Ok(Some(ValidationIssue {
                            field_path: field_path.to_string(),
                            severity: ValidationSeverity::Error,
                            message: "Expected duration value (number of seconds or duration string)".to_string(),
                            suggestion: Some("Use format like '30s', '5m', '1h' or number of seconds".to_string()),
                            rule_name: "type_mismatch".to_string(),
                        }));
                    }
                };
                
                if let Some(min_duration) = min {
                    if duration < *min_duration {
                        return Ok(Some(ValidationIssue {
                            field_path: field_path.to_string(),
                            severity: ValidationSeverity::Error,
                            message: format!("Duration {:?} is below minimum {:?}", duration, min_duration),
                            suggestion: None,
                            rule_name: "duration_min".to_string(),
                        }));
                    }
                }
                
                if let Some(max_duration) = max {
                    if duration > *max_duration {
                        return Ok(Some(ValidationIssue {
                            field_path: field_path.to_string(),
                            severity: ValidationSeverity::Error,
                            message: format!("Duration {:?} is above maximum {:?}", duration, max_duration),
                            suggestion: None,
                            rule_name: "duration_max".to_string(),
                        }));
                    }
                }
            }
            
            FieldConstraint::Custom(validator_name) => {
                if let Some(validator) = self.custom_validators.get(validator_name) {
                    let context = ValidationContext {
                        field_path: field_path.to_string(),
                        full_config: Table::new(), // Would be populated with full config
                        environment: "development".to_string(), // Would be actual environment
                    };
                    
                    if let Err(e) = validator.validate(value, &context) {
                        return Ok(Some(ValidationIssue {
                            field_path: field_path.to_string(),
                            severity: ValidationSeverity::Error,
                            message: e.to_string(),
                            suggestion: None,
                            rule_name: validator_name.clone(),
                        }));
                    }
                }
            }
            
            _ => {
                // Handle other constraint types
            }
        }
        
        Ok(None)
    }
    
    /// Register built-in validators
    fn register_builtin_validators(&mut self) {
        // URL validator
        self.custom_validators.insert(
            "url".to_string(),
            Box::new(UrlValidator),
        );
        
        // File path validator
        self.custom_validators.insert(
            "file_path".to_string(),
            Box::new(FilePathValidator),
        );
        
        // API key validator
        self.custom_validators.insert(
            "api_key".to_string(),
            Box::new(ApiKeyValidator),
        );
        
        // Performance consistency validator
        self.custom_validators.insert(
            "performance_consistency".to_string(),
            Box::new(PerformanceConsistencyValidator),
        );
    }
}

/// URL validator
struct UrlValidator;

impl CustomValidator for UrlValidator {
    fn validate(&self, value: &Value, _context: &ValidationContext) -> Result<(), ValidationError> {
        if let Some(url_str) = value.as_str() {
            url::Url::parse(url_str)
                .map_err(|e| ValidationError::InvalidUrl(e.to_string()))?;
            Ok(())
        } else {
            Err(ValidationError::TypeMismatch("string".to_string()))
        }
    }
    
    fn name(&self) -> &str {
        "url"
    }
}

/// File path validator
struct FilePathValidator;

impl CustomValidator for FilePathValidator {
    fn validate(&self, value: &Value, _context: &ValidationContext) -> Result<(), ValidationError> {
        if let Some(path_str) = value.as_str() {
            let path = Path::new(path_str);
            
            // Check if path is valid (basic validation)
            if path_str.is_empty() {
                return Err(ValidationError::EmptyPath);
            }
            
            // Check for invalid characters (platform-specific)
            if cfg!(windows) {
                let invalid_chars = ['<', '>', ':', '"', '|', '?', '*'];
                if path_str.chars().any(|c| invalid_chars.contains(&c)) {
                    return Err(ValidationError::InvalidPathCharacters);
                }
            }
            
            Ok(())
        } else {
            Err(ValidationError::TypeMismatch("string".to_string()))
        }
    }
    
    fn name(&self) -> &str {
        "file_path"
    }
}

/// API key validator
struct ApiKeyValidator;

impl CustomValidator for ApiKeyValidator {
    fn validate(&self, value: &Value, _context: &ValidationContext) -> Result<(), ValidationError> {
        if let Some(api_key) = value.as_str() {
            // Check if it's a valid API key format
            if api_key.starts_with("sk-") && api_key.len() >= 20 {
                Ok(())
            } else if api_key.starts_with("${") && api_key.ends_with("}") {
                // Environment variable reference
                Ok(())
            } else {
                Err(ValidationError::InvalidApiKeyFormat)
            }
        } else {
            Err(ValidationError::TypeMismatch("string".to_string()))
        }
    }
    
    fn name(&self) -> &str {
        "api_key"
    }
}
```

### 3. Environment-Specific Configuration

```rust
/// Environment-specific configuration overrides
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EnvironmentOverrides {
    /// Environment name
    pub name: String,
    
    /// Description of this environment
    pub description: Option<String>,
    
    /// Configuration overrides
    pub overrides: Table,
    
    /// Environment-specific feature flags
    pub features: HashMap<String, bool>,
    
    /// Environment variables to set
    pub environment_variables: HashMap<String, String>,
    
    /// Resource limits for this environment
    pub resource_limits: Option<ResourceLimits>,
    
    /// Security settings overrides
    pub security_overrides: Option<SecurityOverrides>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SecurityOverrides {
    /// Whether to enable debug logging
    pub debug_logging: bool,
    
    /// Whether to enable development tools
    pub development_tools: bool,
    
    /// API key validation strictness
    pub api_key_validation: ApiKeyValidation,
    
    /// Whitelist enforcement level
    pub whitelist_enforcement: WhitelistEnforcement,
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub enum ApiKeyValidation {
    Strict,   // Full validation required
    Relaxed,  // Basic validation
    Disabled, // No validation (development only)
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub enum WhitelistEnforcement {
    Strict,   // Whitelist always enforced
    Relaxed,  // Whitelist enforced with warnings
    Disabled, // Whitelist disabled (development only)
}

/// Environment processor for handling environment-specific configuration
pub struct EnvironmentProcessor {
    /// Current environment name
    current_environment: Arc<RwLock<String>>,
    
    /// Environment variable resolver
    env_resolver: Arc<EnvironmentVariableResolver>,
    
    /// Environment-specific validators
    env_validators: HashMap<String, Box<dyn EnvironmentValidator + Send + Sync>>,
}

pub trait EnvironmentValidator: Send + Sync {
    fn validate_for_environment(
        &self,
        config: &AppConfiguration,
        environment: &str,
    ) -> Result<Vec<EnvironmentValidationIssue>, ConfigError>;
}

#[derive(Debug, Clone)]
pub struct EnvironmentValidationIssue {
    pub field_path: String,
    pub environment: String,
    pub severity: ValidationSeverity,
    pub message: String,
    pub recommendation: Option<String>,
}

impl EnvironmentProcessor {
    pub fn new() -> Self {
        Self {
            current_environment: Arc::new(RwLock::new("development".to_string())),
            env_resolver: Arc::new(EnvironmentVariableResolver::new()),
            env_validators: HashMap::new(),
        }
    }
    
    /// Set current environment
    pub async fn set_environment(&self, environment: String) {
        *self.current_environment.write().await = environment;
    }
    
    /// Process environment variables in configuration
    pub async fn process_env_vars(&self, config: &mut Table) -> Result<(), ConfigError> {
        self.process_table_env_vars(config).await
    }
    
    /// Recursively process environment variables in a table
    async fn process_table_env_vars(&self, table: &mut Table) -> Result<(), ConfigError> {
        for (_, value) in table.iter_mut() {
            match value {
                Value::String(s) => {
                    if let Some(resolved) = self.env_resolver.resolve_env_var(s).await? {
                        *s = resolved;
                    }
                }
                Value::Table(t) => {
                    self.process_table_env_vars(t).await?;
                }
                Value::Array(arr) => {
                    for item in arr.iter_mut() {
                        if let Value::String(s) = item {
                            if let Some(resolved) = self.env_resolver.resolve_env_var(s).await? {
                                *s = resolved;
                            }
                        }
                    }
                }
                _ => {}
            }
        }
        Ok(())
    }
    
    /// Apply environment-specific overrides
    pub async fn apply_environment_overrides(
        &self,
        config: &mut AppConfiguration,
    ) -> Result<(), ConfigError> {
        let env_name = self.current_environment.read().await.clone();
        
        if let Some(env_overrides) = config.environments.get(&env_name) {
            // Apply configuration overrides
            let override_config = toml::from_str::<AppConfiguration>(
                &toml::to_string(&env_overrides.overrides)?
            )?;
            
            // Merge overrides into main config
            self.merge_configurations(config, override_config).await?;
            
            // Apply feature flag overrides
            for (flag, value) in &env_overrides.features {
                config.app.features.insert(flag.clone(), *value);
            }
            
            // Apply resource limit overrides
            if let Some(resource_limits) = &env_overrides.resource_limits {
                config.app.limits = resource_limits.clone();
            }
            
            // Apply security overrides
            if let Some(security_overrides) = &env_overrides.security_overrides {
                self.apply_security_overrides(config, security_overrides).await?;
            }
        }
        
        Ok(())
    }
    
    /// Apply security overrides
    async fn apply_security_overrides(
        &self,
        config: &mut AppConfiguration,
        overrides: &SecurityOverrides,
    ) -> Result<(), ConfigError> {
        // Apply debug logging setting
        config.logging.level = if overrides.debug_logging {
            "debug".to_string()
        } else {
            "info".to_string()
        };
        
        // Apply development tools setting
        config.development.enable_debug_tools = overrides.development_tools;
        
        // Apply API key validation
        match overrides.api_key_validation {
            ApiKeyValidation::Disabled => {
                config.security.authentication.require_api_key = false;
            }
            _ => {
                config.security.authentication.require_api_key = true;
            }
        }
        
        Ok(())
    }
    
    /// Validate configuration for specific environment
    pub async fn validate_for_environment(
        &self,
        config: &AppConfiguration,
    ) -> Result<Vec<EnvironmentValidationIssue>, ConfigError> {
        let env_name = self.current_environment.read().await.clone();
        let mut issues = Vec::new();
        
        // Production environment validations
        if env_name == "production" {
            issues.extend(self.validate_production_config(config).await?);
        }
        
        // Development environment validations
        if env_name == "development" {
            issues.extend(self.validate_development_config(config).await?);
        }
        
        // Apply environment-specific validators
        for validator in self.env_validators.values() {
            issues.extend(validator.validate_for_environment(config, &env_name)?);
        }
        
        Ok(issues)
    }
    
    /// Validate production environment configuration
    async fn validate_production_config(
        &self,
        config: &AppConfiguration,
    ) -> Result<Vec<EnvironmentValidationIssue>, ConfigError> {
        let mut issues = Vec::new();
        
        // Ensure debug logging is disabled
        if config.logging.level == "debug" || config.logging.level == "trace" {
            issues.push(EnvironmentValidationIssue {
                field_path: "logging.level".to_string(),
                environment: "production".to_string(),
                severity: ValidationSeverity::Warning,
                message: "Debug logging is enabled in production".to_string(),
                recommendation: Some("Set logging level to 'info' or 'warn' for production".to_string()),
            });
        }
        
        // Ensure development tools are disabled
        if config.development.enable_debug_tools {
            issues.push(EnvironmentValidationIssue {
                field_path: "development.enable_debug_tools".to_string(),
                environment: "production".to_string(),
                severity: ValidationSeverity::Error,
                message: "Debug tools are enabled in production".to_string(),
                recommendation: Some("Disable debug tools for production".to_string()),
            });
        }
        
        // Ensure proper resource limits
        if config.app.limits.max_memory_mb < 1024 {
            issues.push(EnvironmentValidationIssue {
                field_path: "app.limits.max_memory_mb".to_string(),
                environment: "production".to_string(),
                severity: ValidationSeverity::Warning,
                message: "Memory limit may be too low for production workloads".to_string(),
                recommendation: Some("Consider increasing memory limit to at least 1GB".to_string()),
            });
        }
        
        // Ensure security settings are appropriate
        if !config.security.authentication.require_api_key {
            issues.push(EnvironmentValidationIssue {
                field_path: "security.authentication.require_api_key".to_string(),
                environment: "production".to_string(),
                severity: ValidationSeverity::Error,
                message: "API key authentication is disabled in production".to_string(),
                recommendation: Some("Enable API key authentication for production".to_string()),
            });
        }
        
        Ok(issues)
    }
    
    /// Validate development environment configuration
    async fn validate_development_config(
        &self,
        config: &AppConfiguration,
    ) -> Result<Vec<EnvironmentValidationIssue>, ConfigError> {
        let mut issues = Vec::new();
        
        // Warn about production-level security in development
        if config.security.whitelist.enforcement_level == "strict" {
            issues.push(EnvironmentValidationIssue {
                field_path: "security.whitelist.enforcement_level".to_string(),
                environment: "development".to_string(),
                severity: ValidationSeverity::Info,
                message: "Strict whitelist enforcement in development environment".to_string(),
                recommendation: Some("Consider using 'relaxed' enforcement for easier development".to_string()),
            });
        }
        
        // Suggest enabling debug features
        if !config.development.enable_debug_tools {
            issues.push(EnvironmentValidationIssue {
                field_path: "development.enable_debug_tools".to_string(),
                environment: "development".to_string(),
                severity: ValidationSeverity::Info,
                message: "Debug tools are disabled in development".to_string(),
                recommendation: Some("Consider enabling debug tools for development".to_string()),
            });
        }
        
        Ok(issues)
    }
}
```

### 4. Configuration Migration System

```rust
/// Configuration migration system for handling version upgrades
pub struct ConfigurationMigrator {
    /// Available migrations
    migrations: Vec<Box<dyn ConfigurationMigration + Send + Sync>>,
    
    /// Migration history
    history: Arc<RwLock<MigrationHistory>>,
    
    /// Version detector
    version_detector: Arc<ConfigVersionDetector>,
}

/// Migration trait
#[async_trait]
pub trait ConfigurationMigration: Send + Sync {
    /// Source version this migration applies to
    fn from_version(&self) -> &str;
    
    /// Target version this migration produces
    fn to_version(&self) -> &str;
    
    /// Migration description
    fn description(&self) -> &str;
    
    /// Check if this migration is applicable
    async fn is_applicable(&self, config: &Table) -> Result<bool, MigrationError>;
    
    /// Perform the migration
    async fn migrate(&self, config: Table) -> Result<Table, MigrationError>;
    
    /// Validate the migrated configuration
    async fn validate_migration(&self, original: &Table, migrated: &Table) -> Result<(), MigrationError>;
}

#[derive(Debug, Clone)]
pub struct MigrationHistory {
    pub migrations: Vec<MigrationRecord>,
}

#[derive(Debug, Clone)]
pub struct MigrationRecord {
    pub id: Uuid,
    pub from_version: String,
    pub to_version: String,
    pub migration_name: String,
    pub applied_at: DateTime<Utc>,
    pub duration: std::time::Duration,
    pub success: bool,
    pub error: Option<String>,
}

/// Example migration: v1.0 to v1.1
pub struct V1_0_to_V1_1_Migration;

#[async_trait]
impl ConfigurationMigration for V1_0_to_V1_1_Migration {
    fn from_version(&self) -> &str {
        "1.0"
    }
    
    fn to_version(&self) -> &str {
        "1.1"
    }
    
    fn description(&self) -> &str {
        "Migrate from v1.0 to v1.1: Add streaming configuration section"
    }
    
    async fn is_applicable(&self, config: &Table) -> Result<bool, MigrationError> {
        // Check if this is a v1.0 config without streaming section
        Ok(!config.contains_key("streaming") && 
           config.get("app")
               .and_then(|v| v.as_table())
               .and_then(|t| t.get("version"))
               .and_then(|v| v.as_str())
               .map(|v| v.starts_with("1.0"))
               .unwrap_or(false))
    }
    
    async fn migrate(&self, mut config: Table) -> Result<Table, MigrationError> {
        // Add default streaming configuration
        let streaming_config = toml::toml! {
            [sse]
            max_connections = 100
            connection_timeout = "30s"
            heartbeat_interval = "30s"
            buffer_size = 1000
            
            [routing]
            enable_filtering = true
            enable_batching = true
            
            [optimization]
            enable_adaptive_quality = true
            enable_compression = true
        };
        
        config.insert("streaming".to_string(), Value::Table(streaming_config));
        
        // Update version
        if let Some(app_section) = config.get_mut("app").and_then(|v| v.as_table_mut()) {
            app_section.insert("version".to_string(), Value::String("1.1.0".to_string()));
        }
        
        Ok(config)
    }
    
    async fn validate_migration(&self, _original: &Table, migrated: &Table) -> Result<(), MigrationError> {
        // Ensure streaming section was added
        if !migrated.contains_key("streaming") {
            return Err(MigrationError::ValidationFailed(
                "Streaming section was not added".to_string()
            ));
        }
        
        // Ensure version was updated
        let version = migrated
            .get("app")
            .and_then(|v| v.as_table())
            .and_then(|t| t.get("version"))
            .and_then(|v| v.as_str())
            .unwrap_or("");
            
        if !version.starts_with("1.1") {
            return Err(MigrationError::ValidationFailed(
                "Version was not updated correctly".to_string()
            ));
        }
        
        Ok(())
    }
}

impl ConfigurationMigrator {
    pub fn new() -> Self {
        let mut migrator = Self {
            migrations: Vec::new(),
            history: Arc::new(RwLock::new(MigrationHistory { migrations: Vec::new() })),
            version_detector: Arc::new(ConfigVersionDetector::new()),
        };
        
        // Register built-in migrations
        migrator.register_builtin_migrations();
        
        migrator
    }
    
    /// Migrate configuration to latest version
    pub async fn migrate_to_latest(&self, config: Table) -> Result<Table, MigrationError> {
        let current_version = self.version_detector.detect_version(&config).await?;
        let target_version = self.get_latest_version();
        
        if current_version == target_version {
            return Ok(config); // No migration needed
        }
        
        // Find migration path
        let migration_path = self.find_migration_path(&current_version, &target_version)?;
        
        // Apply migrations in sequence
        let mut current_config = config;
        
        for migration in migration_path {
            let start_time = std::time::Instant::now();
            
            // Check if migration is applicable
            if !migration.is_applicable(&current_config).await? {
                continue;
            }
            
            // Perform migration
            let migrated_config = migration.migrate(current_config.clone()).await?;
            
            // Validate migration
            migration.validate_migration(&current_config, &migrated_config).await?;
            
            // Record migration
            let duration = start_time.elapsed();
            self.record_migration(migration.as_ref(), duration, true, None).await;
            
            current_config = migrated_config;
        }
        
        Ok(current_config)
    }
    
    /// Find migration path from source to target version
    fn find_migration_path(
        &self,
        from_version: &str,
        to_version: &str,
    ) -> Result<Vec<&Box<dyn ConfigurationMigration + Send + Sync>>, MigrationError> {
        // Simple linear migration path for now
        // In a more complex system, this would use graph algorithms
        
        let mut path = Vec::new();
        let mut current_version = from_version.to_string();
        
        while current_version != to_version {
            let next_migration = self.migrations
                .iter()
                .find(|m| m.from_version() == current_version)
                .ok_or_else(|| MigrationError::NoMigrationPath {
                    from: current_version.clone(),
                    to: to_version.to_string(),
                })?;
            
            path.push(next_migration);
            current_version = next_migration.to_version().to_string();
        }
        
        Ok(path)
    }
    
    /// Register built-in migrations
    fn register_builtin_migrations(&mut self) {
        self.migrations.push(Box::new(V1_0_to_V1_1_Migration));
        // Add more migrations as needed
    }
    
    /// Record migration in history
    async fn record_migration(
        &self,
        migration: &dyn ConfigurationMigration,
        duration: std::time::Duration,
        success: bool,
        error: Option<String>,
    ) {
        let record = MigrationRecord {
            id: Uuid::new_v4(),
            from_version: migration.from_version().to_string(),
            to_version: migration.to_version().to_string(),
            migration_name: migration.description().to_string(),
            applied_at: Utc::now(),
            duration,
            success,
            error,
        };
        
        self.history.write().await.migrations.push(record);
    }
}
```

### 5. Hot-Reloading and Configuration Monitoring

```rust
/// Configuration monitoring and hot-reloading system
pub struct ConfigurationMonitor {
    /// Configuration manager
    config_manager: Arc<ConfigurationManager>,
    
    /// File watchers
    file_watchers: HashMap<PathBuf, Arc<FileWatcher>>,
    
    /// Change detection
    change_detector: Arc<ConfigChangeDetector>,
    
    /// Hot-reload coordinator
    reload_coordinator: Arc<HotReloadCoordinator>,
    
    /// Configuration subscribers
    subscribers: Arc<RwLock<HashMap<String, ConfigSubscriber>>>,
}

/// Configuration change event
#[derive(Debug, Clone)]
pub enum ConfigurationEvent {
    /// Configuration loaded
    Loaded,
    
    /// Configuration updated
    Updated(ConfigSection),
    
    /// Configuration validation failed
    ValidationFailed(Vec<String>),
    
    /// File changed
    FileChanged(PathBuf),
    
    /// Hot-reload completed
    HotReloadCompleted,
    
    /// Hot-reload failed
    HotReloadFailed(String),
}

/// Configuration subscriber for components that need config updates
pub struct ConfigSubscriber {
    pub name: String,
    pub sections: HashSet<ConfigSection>,
    pub sender: mpsc::UnboundedSender<ConfigurationEvent>,
    pub last_notified: DateTime<Utc>,
}

/// Hot-reload coordinator for managing safe configuration updates
pub struct HotReloadCoordinator {
    /// Components that need notification
    components: Arc<RwLock<HashMap<String, Box<dyn ConfigurableComponent + Send + Sync>>>>,
    
    /// Reload strategies
    strategies: HashMap<ConfigSection, ReloadStrategy>,
    
    /// Safety checks
    safety_checker: Arc<ReloadSafetyChecker>,
}

/// Component that can be dynamically reconfigured
#[async_trait]
pub trait ConfigurableComponent: Send + Sync {
    /// Component name
    fn name(&self) -> &str;
    
    /// Configuration sections this component depends on
    fn config_sections(&self) -> HashSet<ConfigSection>;
    
    /// Check if component can safely reload configuration
    async fn can_reload(&self, section: ConfigSection) -> bool;
    
    /// Apply new configuration
    async fn apply_config(&mut self, config: &AppConfiguration) -> Result<(), ConfigError>;
    
    /// Validate configuration before applying
    async fn validate_config(&self, config: &AppConfiguration) -> Result<(), ConfigError>;
    
    /// Get component's current configuration state
    async fn get_config_state(&self) -> ComponentConfigState;
}

#[derive(Debug, Clone)]
pub struct ComponentConfigState {
    pub component_name: String,
    pub last_updated: DateTime<Utc>,
    pub current_config_hash: String,
    pub is_healthy: bool,
    pub pending_changes: Vec<String>,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ReloadStrategy {
    /// Immediate reload without disruption
    Immediate,
    
    /// Graceful reload with brief pause
    Graceful,
    
    /// Requires restart (cannot hot-reload)
    RestartRequired,
    
    /// Custom reload strategy
    Custom,
}

impl ConfigurationMonitor {
    pub fn new(config_manager: Arc<ConfigurationManager>) -> Self {
        Self {
            config_manager,
            file_watchers: HashMap::new(),
            change_detector: Arc::new(ConfigChangeDetector::new()),
            reload_coordinator: Arc::new(HotReloadCoordinator::new()),
            subscribers: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    /// Start monitoring configuration files
    pub async fn start_monitoring(&mut self, file_paths: Vec<PathBuf>) -> Result<(), ConfigError> {
        for path in file_paths {
            let watcher = Arc::new(FileWatcher::new(path.clone())?);
            
            // Start watching this file
            let monitor = self.clone();
            let path_clone = path.clone();
            
            tokio::spawn(async move {
                let mut events = watcher.watch().await;
                
                while let Some(event) = events.next().await {
                    monitor.handle_file_change(&path_clone, event).await;
                }
            });
            
            self.file_watchers.insert(path, watcher);
        }
        
        Ok(())
    }
    
    /// Handle file change event
    async fn handle_file_change(&self, path: &PathBuf, event: FileEvent) {
        match event {
            FileEvent::Modified => {
                // Debounce file changes (wait for writes to complete)
                tokio::time::sleep(std::time::Duration::from_millis(100)).await;
                
                // Attempt hot-reload
                if let Err(e) = self.perform_hot_reload(path).await {
                    eprintln!("Hot-reload failed for {}: {}", path.display(), e);
                    
                    // Notify subscribers of failure
                    let event = ConfigurationEvent::HotReloadFailed(e.to_string());
                    self.notify_subscribers(event).await;
                } else {
                    // Notify subscribers of success
                    let event = ConfigurationEvent::HotReloadCompleted;
                    self.notify_subscribers(event).await;
                }
            }
            _ => {
                // Handle other file events if needed
            }
        }
    }
    
    /// Perform hot-reload of configuration
    async fn perform_hot_reload(&self, _path: &PathBuf) -> Result<(), ConfigError> {
        // Load new configuration
        let new_config = self.config_manager.load_configuration().await?;
        
        // Perform safety checks
        self.reload_coordinator
            .safety_checker
            .check_reload_safety(&new_config)
            .await?;
        
        // Apply configuration to components
        self.reload_coordinator
            .apply_configuration_to_components(&new_config)
            .await?;
        
        Ok(())
    }
    
    /// Subscribe to configuration changes
    pub async fn subscribe(
        &self,
        subscriber: ConfigSubscriber,
    ) -> mpsc::UnboundedReceiver<ConfigurationEvent> {
        let (tx, rx) = mpsc::unbounded_channel();
        
        let subscriber_with_sender = ConfigSubscriber {
            sender: tx,
            ..subscriber
        };
        
        self.subscribers
            .write()
            .await
            .insert(subscriber_with_sender.name.clone(), subscriber_with_sender);
        
        rx
    }
    
    /// Notify all subscribers of configuration change
    async fn notify_subscribers(&self, event: ConfigurationEvent) {
        let subscribers = self.subscribers.read().await;
        
        for subscriber in subscribers.values() {
            // Check if subscriber is interested in this event
            let should_notify = match &event {
                ConfigurationEvent::Updated(section) => {
                    subscriber.sections.contains(section)
                }
                _ => true, // Notify of all other events
            };
            
            if should_notify {
                let _ = subscriber.sender.send(event.clone());
            }
        }
    }
    
    /// Register a configurable component
    pub async fn register_component(
        &self,
        component: Box<dyn ConfigurableComponent + Send + Sync>,
    ) {
        let component_name = component.name().to_string();
        self.reload_coordinator
            .components
            .write()
            .await
            .insert(component_name, component);
    }
    
    /// Get configuration monitoring status
    pub async fn get_monitoring_status(&self) -> ConfigMonitoringStatus {
        let subscribers = self.subscribers.read().await;
        let components = self.reload_coordinator.components.read().await;
        
        ConfigMonitoringStatus {
            files_watched: self.file_watchers.len(),
            subscribers_count: subscribers.len(),
            components_count: components.len(),
            last_reload: self.get_last_reload_time().await,
            is_monitoring: !self.file_watchers.is_empty(),
        }
    }
}

#[derive(Debug, Clone)]
pub struct ConfigMonitoringStatus {
    pub files_watched: usize,
    pub subscribers_count: usize,
    pub components_count: usize,
    pub last_reload: Option<DateTime<Utc>>,
    pub is_monitoring: bool,
}
```

## Architecture Changes

### Current Architecture
```

 Basic Config    

 Hardcoded Values
 No Validation   
 Static Settings 

```

### Target Architecture
```

                Comprehensive Configuration System               

    
     TOML       Validation       Environment-Specific    
    Schema       & Schema        Configuration Profiles  
   & Parsing    Enforcement                              
    

    
  Hot-reload    Migration        Configuration           
 & Monitoring   & Versioning     Sources & Merging       
    

```

## Implementation Plan

### Phase 1: TOML Schema Foundation (Week 1-2)
1. Implement comprehensive `AppConfiguration` structure
2. Create `ConfigurationManager` with source loading
3. Build TOML parsing and validation
4. Set up environment variable processing

### Phase 2: Validation System (Week 2-3)
1. Implement `ConfigValidator` with schema enforcement
2. Create custom validation rules and constraints
3. Build field dependency validation
4. Add environment-specific validation

### Phase 3: Environment Support (Week 3-4)
1. Implement environment-specific configuration profiles
2. Create `EnvironmentProcessor` for overrides
3. Build environment validation rules
4. Add security configuration per environment

### Phase 4: Migration & Versioning (Week 4-5)
1. Implement configuration migration system
2. Create version detection and upgrade paths
3. Build migration validation and rollback
4. Add migration history tracking

### Phase 5: Hot-Reloading & Monitoring (Week 5-6)
1. Implement configuration file monitoring
2. Create hot-reload coordination system
3. Build component notification system
4. Add configuration change streaming

## Testing Strategy

### Unit Tests

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_configuration_loading() {
        let mut manager = ConfigurationManager::new();
        
        // Add file source
        manager.add_source(Box::new(FileConfigurationSource {
            file_path: PathBuf::from("test_config.toml"),
            watch_enabled: false,
        }));
        
        // Load configuration
        manager.load_configuration().await.unwrap();
        
        // Verify configuration
        let config = manager.get_config().await;
        assert_eq!(config.app.name, "test-app");
        assert_eq!(config.app.environment, "test");
    }
    
    #[tokio::test]
    async fn test_configuration_validation() {
        let validator = ConfigValidator::new();
        
        let mut config = Table::new();
        config.insert("app".to_string(), toml::toml! {
            name = "test-app"
            version = "1.0.0"
            environment = "test"
            mode = "Development"
        });
        
        let result = validator.validate_table(&config).await.unwrap();
        assert!(result.is_valid);
        assert!(result.issues.is_empty());
    }
    
    #[tokio::test]
    async fn test_environment_overrides() {
        let processor = EnvironmentProcessor::new();
        processor.set_environment("production".to_string()).await;
        
        let mut config = create_test_config();
        processor.apply_environment_overrides(&mut config).await.unwrap();
        
        // Verify production-specific settings were applied
        assert_eq!(config.logging.level, "info");
        assert!(!config.development.enable_debug_tools);
    }
    
    #[tokio::test]
    async fn test_configuration_migration() {
        let migrator = ConfigurationMigrator::new();
        
        let old_config = create_v1_0_config();
        let migrated = migrator.migrate_to_latest(old_config).await.unwrap();
        
        // Verify migration was applied
        assert!(migrated.contains_key("streaming"));
        
        let version = migrated
            .get("app")
            .unwrap()
            .as_table()
            .unwrap()
            .get("version")
            .unwrap()
            .as_str()
            .unwrap();
        
        assert!(version.starts_with("1.1"));
    }
    
    #[tokio::test]
    async fn test_hot_reload() {
        let config_manager = Arc::new(ConfigurationManager::new());
        let mut monitor = ConfigurationMonitor::new(config_manager);
        
        // Subscribe to changes
        let subscriber = ConfigSubscriber {
            name: "test_subscriber".to_string(),
            sections: HashSet::from([ConfigSection::App]),
            sender: mpsc::unbounded_channel().0,
            last_notified: Utc::now(),
        };
        
        let mut receiver = monitor.subscribe(subscriber).await;
        
        // Simulate file change
        tokio::spawn(async move {
            tokio::time::sleep(std::time::Duration::from_millis(100)).await;
            // Would trigger file change event in real implementation
        });
        
        // Wait for notification
        let event = tokio::time::timeout(
            std::time::Duration::from_secs(1),
            receiver.recv()
        ).await;
        
        assert!(event.is_ok());
    }
}
```

### Integration Tests

```rust
#[tokio::test]
async fn test_end_to_end_configuration() {
    // Create temporary config file
    let config_content = r#"
        [app]
        name = "integration-test"
        version = "1.0.0"
        environment = "test"
        mode = "Development"
        
        [claude]
        [claude.api]
        base_url = "https://api.anthropic.com"
        api_key = "${CLAUDE_API_KEY}"
        timeout = "30s"
        
        [tools]
        [tools.execution]
        default_timeout = "60s"
        max_concurrent = 10
        
        [streaming]
        [streaming.sse]
        max_connections = 100
        connection_timeout = "30s"
    "#;
    
    let temp_file = write_temp_config(config_content).await;
    
    // Set up configuration manager
    let mut manager = ConfigurationManager::new();
    manager.add_source(Box::new(FileConfigurationSource {
        file_path: temp_file.clone(),
        watch_enabled: true,
    }));
    
    // Set environment variable
    std::env::set_var("CLAUDE_API_KEY", "sk-test-key-123");
    
    // Load configuration
    manager.load_configuration().await.unwrap();
    
    // Verify configuration
    let config = manager.get_config().await;
    assert_eq!(config.app.name, "integration-test");
    assert!(config.claude.api.api_key.contains("sk-test-key-123"));
    assert_eq!(config.tools.execution.max_concurrent, 10);
    
    // Test hot-reload
    let updated_content = config_content.replace("max_concurrent = 10", "max_concurrent = 20");
    write_config_file(&temp_file, &updated_content).await;
    
    // Wait for hot-reload
    tokio::time::sleep(std::time::Duration::from_millis(500)).await;
    
    // Verify update
    let updated_config = manager.get_config().await;
    assert_eq!(updated_config.tools.execution.max_concurrent, 20);
    
    cleanup_temp_file(&temp_file).await;
}

#[tokio::test]
async fn test_environment_specific_configuration() {
    let base_config = create_base_config_toml();
    let production_overrides = create_production_overrides_toml();
    
    // Test production environment
    std::env::set_var("APP_ENVIRONMENT", "production");
    
    let config = load_config_with_environment(base_config, production_overrides).await;
    
    // Verify production settings
    assert_eq!(config.logging.level, "info");
    assert!(!config.development.enable_debug_tools);
    assert!(config.security.authentication.require_api_key);
    
    // Test development environment
    std::env::set_var("APP_ENVIRONMENT", "development");
    
    let dev_config = load_config_with_environment(base_config, "").await;
    
    // Verify development settings
    assert_eq!(dev_config.logging.level, "debug");
    assert!(dev_config.development.enable_debug_tools);
}
```

### Performance Tests

```rust
#[tokio::test]
async fn benchmark_configuration_loading() {
    let large_config = create_large_config_file().await;
    let manager = ConfigurationManager::new();
    
    // Measure loading time
    let start = std::time::Instant::now();
    
    for _ in 0..100 {
        manager.load_configuration().await.unwrap();
    }
    
    let duration = start.elapsed();
    let avg_time = duration / 100;
    
    println!("Average config loading time: {:?}", avg_time);
    assert!(avg_time < std::time::Duration::from_millis(10));
}

#[tokio::test]
async fn stress_test_hot_reload() {
    let config_manager = Arc::new(ConfigurationManager::new());
    let monitor = ConfigurationMonitor::new(config_manager);
    
    // Create many subscribers
    let mut receivers = Vec::new();
    for i in 0..100 {
        let subscriber = ConfigSubscriber {
            name: format!("subscriber_{}", i),
            sections: HashSet::from([ConfigSection::App]),
            sender: mpsc::unbounded_channel().0,
            last_notified: Utc::now(),
        };
        
        let receiver = monitor.subscribe(subscriber).await;
        receivers.push(receiver);
    }
    
    // Simulate rapid configuration changes
    let start = std::time::Instant::now();
    
    for _ in 0..50 {
        // Simulate configuration update
        monitor.notify_subscribers(ConfigurationEvent::Updated(ConfigSection::App)).await;
    }
    
    let duration = start.elapsed();
    println!("50 updates to 100 subscribers in {:?}", duration);
    
    // Should handle updates efficiently
    assert!(duration < std::time::Duration::from_millis(100));
}
```

## Dependencies & Integration

### Direct Dependencies
- **Issue 1.5**: Configuration Foundation
  - Extends basic configuration with comprehensive TOML support
  - Required for enhanced configuration management

- **Issue 2.4**: Enhanced Error Handling and Retry Mechanisms
  - Integration for configuration validation and error handling
  - Required for robust configuration processing

### Integration Points
- **All Systems**: Comprehensive configuration for all components
- **Tool System**: Tool-specific configuration settings
- **Workflow System**: Workflow execution configuration
- **Streaming System**: Streaming quality and optimization settings
- **Error Handling**: Error handling strategy configuration

### API Changes
- New configuration management endpoints
- Environment-specific configuration APIs
- Configuration validation and migration endpoints
- Real-time configuration monitoring

## Security Considerations

### Configuration Security
- Secure handling of sensitive configuration values
- Environment variable protection and validation
- Access control for configuration modification

### Hot-Reload Security
- Validation of configuration changes before application
- Prevention of malicious configuration injection
- Audit trail for all configuration changes

### Environment Isolation
- Secure separation of environment-specific settings
- Prevention of development settings in production
- Validation of environment-appropriate configurations

## Acceptance Criteria

1. **TOML Configuration Support**
   - [ ] Complete TOML schema with all system configurations
   - [ ] Support for complex nested configurations
   - [ ] Environment variable interpolation

2. **Configuration Validation**
   - [ ] Comprehensive schema validation with constraints
   - [ ] Custom validation rules and business logic
   - [ ] Environment-specific validation rules

3. **Environment Management**
   - [ ] Environment-specific configuration profiles
   - [ ] Automatic environment detection and overrides
   - [ ] Production vs development configuration validation

4. **Hot-Reloading**
   - [ ] File-based configuration monitoring
   - [ ] Safe hot-reload with component coordination
   - [ ] Rollback capability for failed reloads

5. **Migration Support**
   - [ ] Automatic configuration version detection
   - [ ] Safe migration between configuration versions
   - [ ] Migration history and rollback support

6. **Integration**
   - [ ] All Phase 1 and Phase 2 systems configured via TOML
   - [ ] Real-time configuration updates for all components
   - [ ] Configuration-driven feature flags and settings

## References

- [TOML Specification](https://toml.io/en/)
- [Configuration Best Practices](https://12factor.net/config)
- [Hot Configuration Reloading](https://microservices.io/patterns/externalized-configuration.html)
- [Configuration Schema Validation](https://json-schema.org/)
- [Environment-Specific Configuration](https://docs.spring.io/spring-boot/docs/current/reference/html/features.html#features.profiles)

## Estimated Lines of Code

- TOML configuration schema and parsing: ~400 lines
- Configuration validation system: ~300 lines
- Environment-specific configuration: ~250 lines
- Configuration migration system: ~200 lines
- Hot-reloading and monitoring: ~250 lines
- Integration and utilities: ~100 lines

**Total: ~1,500 lines**